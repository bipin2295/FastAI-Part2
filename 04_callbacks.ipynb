{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_callbacks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "keW9vafuZRP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb2pjVKMaDH7",
        "colab_type": "code",
        "outputId": "7413b033-8fe9-45e5-a01a-5c0fea14a6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "210JrSQAaMmU",
        "colab_type": "code",
        "outputId": "e8cd0136-a54b-43b1-863c-cd00b0b42b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# export\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks/exp\")\n",
        "from nb_03 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPVFJ1C-auSB",
        "colab_type": "text"
      },
      "source": [
        "## Databunch/Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORc4xh7had4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading data\n",
        "x_train, y_train, x_valid, y_valid = get_data()\n",
        "\n",
        "# Creating dataset\n",
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "\n",
        "nh, bs = 50, 64\n",
        "\n",
        "c = y_train.max().item() + 1\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elDR3mffd9FJ",
        "colab_type": "text"
      },
      "source": [
        "Factor out the connected pieces of info out of the `fit()` argument list\n",
        "\n",
        "`fit(epochs, model, loss_func, opt, train_dl, valid_dl)`\n",
        "\n",
        "Let's replace it with something that looks like this:\n",
        "\n",
        "`fit(1, learn)`\n",
        "\n",
        "This will allow us to tweak what's happening inside the training loop in other places of the code because the `Learner` object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZZshU9zdGli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class Databunch():\n",
        "  def __init__(self, train_dl, valid_dl, c = None):\n",
        "    self.train_dl, self.valid_dl, self.c = train_dl, valid_dl, c\n",
        "\n",
        "  @property\n",
        "  def train_ds(self):\n",
        "    return self.train_dl.dataset\n",
        "\n",
        "  @property\n",
        "  def valid_ds(self):\n",
        "    return self.valid_dl.dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ_HMjise3kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = Databunch(*get_dls(train_ds, valid_ds, bs), c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2smti8MgrTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def get_model(data, lr=0.5, nh=50):\n",
        "  m = data.train_ds.x.shape[1]\n",
        "  model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, data.c))\n",
        "  return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "class Learner():\n",
        "  def __init__(self, model, opt, loss_func, data):\n",
        "    self.model, self.opt, self.loss_func, self.data = model, opt, loss_func, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgB1krYfiqwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func=loss_func, data=data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU4HFMfoi3-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, learn):\n",
        "  for epoch in range(epochs):\n",
        "    learn.model.train()\n",
        "    for xb, yb in learn.data.train_dl:\n",
        "      loss = learn.loss_func(learn.model(xb), yb)\n",
        "      loss.backward()\n",
        "      learn.opt.step()\n",
        "      learn.opt.zero_grad()\n",
        "\n",
        "    learn.model.eval()\n",
        "    with torch.no_grad():\n",
        "      tot_loss, tot_acc = 0., 0.\n",
        "      for xb, yb in learn.data.valid_dl:\n",
        "        pred = learn.model(xb)\n",
        "        tot_loss += loss_func(pred, yb)\n",
        "        tot_acc += accuracy(pred, yb)\n",
        "      nv = len(learn.data.valid_dl)\n",
        "      print(f\"Epoch:{epoch}, Total loss: {tot_loss/nv}, Total accuracy:{tot_acc/nv}\")\n",
        "  return tot_loss/nv, tot_acc/nv   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFgGD003mDiG",
        "colab_type": "code",
        "outputId": "7789394d-14b8-4fed-e057-83a6d0dd3f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "loss, acc = fit(10, learn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Total loss: 0.1505986899137497, Total accuracy:0.9547173380851746\n",
            "Epoch:1, Total loss: 0.13680441677570343, Total accuracy:0.9602906107902527\n",
            "Epoch:2, Total loss: 0.21016372740268707, Total accuracy:0.9414808750152588\n",
            "Epoch:3, Total loss: 0.12326689809560776, Total accuracy:0.9669585824012756\n",
            "Epoch:4, Total loss: 0.17335361242294312, Total accuracy:0.9535230994224548\n",
            "Epoch:5, Total loss: 0.09968739748001099, Total accuracy:0.9734275341033936\n",
            "Epoch:6, Total loss: 0.10377616435289383, Total accuracy:0.9722332954406738\n",
            "Epoch:7, Total loss: 0.11310408264398575, Total accuracy:0.9693471193313599\n",
            "Epoch:8, Total loss: 0.09544160217046738, Total accuracy:0.9735270738601685\n",
            "Epoch:9, Total loss: 0.21857768297195435, Total accuracy:0.9453622698783875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zicm5osOkjPC",
        "colab_type": "text"
      },
      "source": [
        "## Callback Handler\n",
        "This was our training loop (without validation) from the previous notebook, with the inner loop contents factored out:\n",
        "```\n",
        "def one_batch(xb,yb):\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for b in train_dl: one_batch(*b)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Add callbacks so we can remove complexity from loop, and make it flexible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FMAdtBMiVtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_batch(xb, yb, cb):\n",
        "  if not cb.begin_batch(xb, yb): return\n",
        "  loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
        "  if not cb.after_loss(loss): return\n",
        "  loss.backward()\n",
        "  if cb.after_backward(): cb.learn.opt.step()\n",
        "  if cb.after_step(): cb.learn.opt.zero_grad()\n",
        "\n",
        "def all_batches(dl, cb):\n",
        "  for xb, yb in dl:\n",
        "    one_batch(xb, yb, cb)\n",
        "    if cb.do_stop(): return\n",
        "\n",
        "def fit(epochs, learn, cb):\n",
        "  if not cb.begin_fit(learn): return\n",
        "  for epoch in range(epochs):\n",
        "    if not cb.begin_epoch(epoch): continue\n",
        "    all_batches(learn.data.train_dl, cb)\n",
        "\n",
        "    if cb.begin_validate():\n",
        "      with torch.no_grad():\n",
        "        all_batches(learn.data.valid_dl, cb)\n",
        "    \n",
        "    if cb.do_stop() or not cb.after_epoch():\n",
        "      break\n",
        "    cb.after_fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBkOoUIUfM0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Callback():\n",
        "  def begin_fit(self, learn):\n",
        "    self.learn = learn\n",
        "    return True\n",
        "\n",
        "  def after_fit(self): return True\n",
        "\n",
        "  def begin_epoch(self, epoch): \n",
        "    self.epoch = epoch\n",
        "    return True\n",
        "\n",
        "  def begin_validate(self): return True\n",
        "\n",
        "  def after_epoch(self): return True\n",
        "\n",
        "  def begin_batch(self, xb, yb):\n",
        "    self.xb, self.yb = xb, yb\n",
        "    return True\n",
        "\n",
        "  def after_loss(self,loss):\n",
        "    self.loss = loss\n",
        "    return True\n",
        "\n",
        "  def after_backward(self): return True\n",
        "\n",
        "  def after_step(self): return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8mp4KsAoUdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CallbackHandler():\n",
        "  def __init__(self, cbs=None):\n",
        "    self.cbs = cbs if cbs else []\n",
        "\n",
        "  def begin_fit(self, learn):\n",
        "    self.learn, self.in_train = learn, True\n",
        "    learn.stop = False\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.begin_fit(learn)\n",
        "    return res\n",
        "\n",
        "  def after_fit(self):\n",
        "    res = not self.in_train\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.after_fit()\n",
        "    return res\n",
        "\n",
        "  def begin_epoch(self, epoch):\n",
        "    self.learn.model.train()\n",
        "    self.in_train = True\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.begin_epoch(epoch)\n",
        "    return res\n",
        "\n",
        "  def begin_validate(self):\n",
        "    self.learn.model.eval()\n",
        "    self.in_train = False\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.begin_validate()\n",
        "    return res\n",
        "\n",
        "  def after_epoch(self):\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.after_epoch()\n",
        "    return res\n",
        "\n",
        "  def begin_batch(self, xb, yb):\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.begin_batch(xb, yb)\n",
        "    return res\n",
        "\n",
        "  def after_loss(self, loss):\n",
        "    res = self.in_train\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.after_loss(loss)\n",
        "    return res\n",
        "\n",
        "  def after_backward(self):\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.after_backward()\n",
        "    return res\n",
        "\n",
        "  def after_step(self):\n",
        "    res = True\n",
        "    for cb in self.cbs:\n",
        "      res = res and cb.after_step()\n",
        "    return res\n",
        "\n",
        "  def do_stop(self):\n",
        "    try:\n",
        "      return self.learn.stop\n",
        "    finally:\n",
        "      self.learn.stop = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2jNuL5NwjL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "  def begin_fit(self, learn):\n",
        "    super().begin_fit(learn)\n",
        "    self.n_iters = 0\n",
        "    return True\n",
        "\n",
        "  def after_step(self):\n",
        "    self.n_iters += 1\n",
        "    print(self.n_iters)\n",
        "    if self.n_iters >= 10:\n",
        "      self.learn.stop = True\n",
        "    return True\n",
        "\n",
        "  def begin_epoch(self, epoch):\n",
        "    self.n_iters = 0\n",
        "    print(f'Epoch {epoch}')\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCZzADvyDXZ",
        "colab_type": "code",
        "outputId": "d52e1ba6-d88d-4b74-88cf-11cee01f29be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "fit(3, learn, cb=CallbackHandler([TestCallback()]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Epoch 1\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "Epoch 2\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsrObmTO0-lb",
        "colab_type": "text"
      },
      "source": [
        "This is roughly how fastai does it now (except that the handler can also change and return xb, yb, and loss). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing cb to so many functions is a strong hint they should all be in the same class!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXc89h5a1I6z",
        "colab_type": "text"
      },
      "source": [
        "## Runner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjcIixg_c3qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "import re\n",
        "\n",
        "_camel_re1 = re.compile('(.+?)([A-Z])')\n",
        "_camel_re2 = re.compile('(.*?)_([a-z0-9A-Z])')\n",
        "\n",
        "def camel2snake(name):\n",
        "  s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
        "  return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
        "\n",
        "class Callback():\n",
        "  _order = 0\n",
        "  def set_runner(self, run):\n",
        "    self.run = run\n",
        "\n",
        "  def __getattr__(self, k):\n",
        "    return getattr(self.run, k)\n",
        "\n",
        "  @property\n",
        "  def name(self):\n",
        "    name = re.sub(r'Callback$','',self.__class__.__name__)\n",
        "    return camel2snake(name or 'callback')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dajCbNN763bn",
        "colab_type": "text"
      },
      "source": [
        "This first callback is reponsible to switch the model back and forth in training or validation mode, as well as maintaining a count of the iterations, or the percentage of iterations ellapsed in the epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T403b1IOcMRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class TrainEvalCallback(Callback):\n",
        "  def begin_fit(self):\n",
        "    self.run.n_epochs = 0.\n",
        "    self.run.n_iter = 0\n",
        "\n",
        "  def after_batch(self):\n",
        "    if not self.in_train: return\n",
        "    self.run.n_epochs += 1./self.iters\n",
        "    self.run.n_iter += 1\n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.run.n_epochs = self.epoch\n",
        "    self.model.train()\n",
        "    self.run.in_train=True\n",
        "\n",
        "  def begin_validate(self):\n",
        "    self.model.eval()\n",
        "    self.run.in_train=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMOUotkW7y4y",
        "colab_type": "text"
      },
      "source": [
        "We'll also re-create our TestCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAaLro537yNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "  def after_step(self):\n",
        "    if self.train_eval.n_iters >= 10:\n",
        "      return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb_uToLB8DHR",
        "colab_type": "code",
        "outputId": "af8c0c74-158c-416d-c93a-8af60d9cacab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cbname = 'TrainEvalCallback'\n",
        "camel2snake(cbname)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval_callback'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPfnnXMZ8J-G",
        "colab_type": "code",
        "outputId": "841dc669-e35d-4133-96c6-905a89bdc10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TrainEvalCallback().name"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7tQQhtX8OIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "\n",
        "from typing import *\n",
        "def listify(o):\n",
        "  if o is None: return []\n",
        "  if isinstance(o, list): return o\n",
        "  if isinstance(o, str): return [o]\n",
        "  if isinstance(o, Iterable): return list(o)\n",
        "  return [o]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx8v9cG18xus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class Runner():\n",
        "  def __init__(self, cbs = None, cb_funcs = None):\n",
        "    cbs = listify(cbs)\n",
        "    for cbf in listify(cb_funcs):\n",
        "      cb = cbf()\n",
        "      setattr(self, cb.name, cb)\n",
        "      cbs.append(cb)\n",
        "    self.stop, self.cbs = False, [TrainEvalCallback()]+cbs\n",
        "\n",
        "  @property\n",
        "  def opt(self):\n",
        "    return self.learn.opt\n",
        "\n",
        "  @property\n",
        "  def model(self):\n",
        "    return self.learn.model\n",
        "\n",
        "  @property\n",
        "  def loss_func(self):\n",
        "    return self.learn.loss_func\n",
        "\n",
        "  @property\n",
        "  def data(self):\n",
        "    return self.learn.data\n",
        "\n",
        "  def one_batch(self, xb, yb):\n",
        "    self.xb, self.yb = xb, yb\n",
        "    if self('begin_batch'): return\n",
        "    self.pred = self.model(self.xb)\n",
        "    \n",
        "    if self('after_pred'): return\n",
        "    self.loss = self.loss_func(self.pred, self.yb)\n",
        "\n",
        "    if self('after_loss') or not self.in_train: return\n",
        "    \n",
        "    self.loss.backward()\n",
        "\n",
        "    if self('after_backward'): return\n",
        "    self.opt.step()\n",
        "\n",
        "    if self('after_step'): return\n",
        "    self.opt.zero_grad()\n",
        "\n",
        "  def all_batches(self, dl):\n",
        "    self.iters = len(dl)\n",
        "    for xb, yb in dl:\n",
        "      if self.stop: break\n",
        "      self.one_batch(xb, yb)\n",
        "      self('after_batch')\n",
        "    self.stop = False\n",
        "\n",
        "  def fit(self, epochs, learn):\n",
        "    self.epochs, self.learn = epochs, learn\n",
        "\n",
        "    try:\n",
        "      for cb in self.cbs: cb.set_runner(self)\n",
        "      if self('begin_fit'): return\n",
        "      for epoch in range(epochs):\n",
        "        self.epoch = epoch\n",
        "        if not self('begin_epoch'): \n",
        "          self.all_batches(self.data.train_dl)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          if not self('begin_validate'):\n",
        "            self.all_batches(self.data.valid_dl)\n",
        "          if self('after_epoch'): break\n",
        "\n",
        "    finally:\n",
        "      self('after_fit')\n",
        "      self.learn = None\n",
        "\n",
        "  def __call__(self, cb_name):\n",
        "    for cb in sorted(self.cbs, key=lambda x: x._order):\n",
        "      f = getattr(cb, cb_name, None)\n",
        "      if f and f(): return True\n",
        "    return False\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YefHjd2bVk2w",
        "colab_type": "text"
      },
      "source": [
        "Third callback: how to compute metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcyEj72VjQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class AvgStats():\n",
        "  def __init__(self, metrics, in_train):\n",
        "    self.metrics, self.in_train = listify(metrics), in_train\n",
        "\n",
        "  def reset(self):\n",
        "    self.tot_loss, self.count = 0.,0\n",
        "    self.tot_mets = [0.] * len(self.metrics)\n",
        "\n",
        "  @property\n",
        "  def all_stats(self):\n",
        "    return [self.tot_loss.item()] + self.tot_mets\n",
        "\n",
        "  @property\n",
        "  def avg_stats(self):\n",
        "    return[o/self.count for o in self.all_stats]\n",
        "\n",
        "  def __repr__(self):\n",
        "    if not self.count: return \"\"\n",
        "    return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
        "\n",
        "  def accumulate(self, run):\n",
        "    bn = run.xb.shape[0]\n",
        "    self.tot_loss += run.loss * bn\n",
        "    self.count += bn\n",
        "    for i,m in enumerate(self.metrics):\n",
        "      self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "  def __init__(self, metrics):\n",
        "    self.train_stats, self.valid_stats = AvgStats(metrics, True), AvgStats(metrics, False)      \n",
        "\n",
        "  def begin_epoch(self):\n",
        "    self.train_stats.reset()\n",
        "    self.valid_stats.reset()\n",
        "\n",
        "  def after_loss(self):\n",
        "    stats = self.train_stats if self.in_train else self.valid_stats\n",
        "    with torch.no_grad():\n",
        "      stats.accumulate(self.run)\n",
        "\n",
        "  def after_epoch(self):\n",
        "    print(self.train_stats)\n",
        "    print(self.valid_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdoPhEEOmZWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPX99JYMmhQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats = AvgStatsCallback([accuracy])\n",
        "run = Runner(cbs=stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRuEjkMAmpq1",
        "colab_type": "code",
        "outputId": "e858ef1e-4f18-40b3-f586-74dcdfb1fe58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "run.fit(2, learn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.3233550390625, tensor(0.9012)]\n",
            "valid: [0.1631866455078125, tensor(0.9514)]\n",
            "train: [0.14649951171875, tensor(0.9556)]\n",
            "valid: [0.182030517578125, tensor(0.9480)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqDp7P7UoYoX",
        "colab_type": "code",
        "outputId": "48385f35-ce07-4b86-a940-3dc139c50c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, acc = stats.valid_stats.avg_stats\n",
        "assert acc > 0.9\n",
        "loss, acc"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.182030517578125, tensor(0.9480))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfOWc9K8rQny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxB6ekz8rfEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_cbf = partial(AvgStatsCallback, accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7zWVZsgqjwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run = Runner(cb_funcs=acc_cbf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXc-4ESDrptO",
        "colab_type": "code",
        "outputId": "26ac400a-e9bb-488d-cf5b-0ae20c4dbdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.10831345703125, tensor(0.9667)]\n",
            "valid: [0.12555631103515624, tensor(0.9618)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvHY1f4brzX6",
        "colab_type": "code",
        "outputId": "4d3ff387-abeb-4208-a984-54be3228a70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "run.avg_stats.valid_stats.avg_stats"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12555631103515624, tensor(0.9618)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YOCGJuDr71d",
        "colab_type": "text"
      },
      "source": [
        "##Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL6mL6Cer4dV",
        "colab_type": "code",
        "outputId": "81b89d6e-7200-402f-8c0f-753d3029e29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=f628b1298f574244a5eb2cb80a8002d1b3d2589b43f3678fcce194e2a92e1617\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jssmaQ-XsMkv",
        "colab_type": "code",
        "outputId": "20745311-916e-489d-bb50-1ea2cafcf77b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!python \"/content/drive/My Drive/Colab Notebooks/notebook2script.py\" \"/content/drive/My Drive/Colab Notebooks/04_callbacks.ipynb\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted /content/drive/My Drive/Colab Notebooks/04_callbacks.ipynb to /content/drive/My Drive/Colab Notebooks/exp/nb_04.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}