{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_minibatch_training",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kSKXyy5EjrHI",
        "HiwvFomemYL-",
        "6yl5TFBqu5LJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21cHknDhksD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8b5e3af-1969-448e-93b6-302963da854f"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpAQ2mO0h1GJ",
        "colab_type": "code",
        "outputId": "7961162a-76bc-4238-de14-3600b6287404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56q5n6QFh3O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks/exp\")\n",
        "from nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklgC6rKjn7r",
        "colab_type": "text"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKXyy5EjrHI",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU7cdM-nhznp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqHQ_O2Sj46s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xZ6cWRvj_lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n, m = x_train.shape\n",
        "c= y_train.max() + 1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n3PZfYLkMga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKThfn4Wl3pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLUfC04vmAFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiwvFomemYL-",
        "colab_type": "text"
      },
      "source": [
        "## Cross Entropy loss\n",
        "\n",
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4X3M1n3meUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrPsrAehmzqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_F2_ptYnmNG",
        "colab_type": "code",
        "outputId": "9a9bf60a-da95-4450-f931-9440a4d18fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "pred, sm_pred"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.1053e-01, -7.2135e-02, -2.6264e-01,  ..., -5.9562e-02,\n",
              "          -9.4913e-02, -1.2401e-01],\n",
              "         [-1.6240e-01, -3.0950e-02, -2.4026e-01,  ...,  1.4663e-02,\n",
              "          -1.0649e-01, -2.0211e-01],\n",
              "         [-8.8474e-02, -1.2782e-01, -1.9942e-01,  ...,  1.0551e-01,\n",
              "           1.1453e-02, -6.6103e-02],\n",
              "         ...,\n",
              "         [-1.4424e-01, -1.9656e-01, -2.2762e-01,  ...,  2.3967e-02,\n",
              "          -5.8659e-02, -2.0482e-01],\n",
              "         [-9.6590e-02, -1.7434e-01, -1.9059e-01,  ...,  6.9588e-05,\n",
              "          -5.9569e-02, -1.4848e-01],\n",
              "         [-1.2940e-01, -1.2655e-01, -2.4920e-01,  ...,  1.5363e-01,\n",
              "           1.0952e-02, -2.2787e-01]], grad_fn=<AddmmBackward>),\n",
              " tensor([[-2.3351, -2.2967, -2.4872,  ..., -2.2841, -2.3195, -2.3486],\n",
              "         [-2.3717, -2.2402, -2.4495,  ..., -2.1946, -2.3158, -2.4114],\n",
              "         [-2.3378, -2.3772, -2.4488,  ..., -2.1438, -2.2379, -2.3155],\n",
              "         ...,\n",
              "         [-2.3566, -2.4089, -2.4400,  ..., -2.1884, -2.2710, -2.4172],\n",
              "         [-2.3177, -2.3955, -2.4117,  ..., -2.2211, -2.2807, -2.3696],\n",
              "         [-2.3440, -2.3412, -2.4638,  ..., -2.0610, -2.2037, -2.4425]],\n",
              "        grad_fn=<LogBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_MP705pJZj",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09zYYQknnRg",
        "colab_type": "code",
        "outputId": "3cb26c3a-dffc-4d0d-9aa4-d647a43a53a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVBHY2DbpaQO",
        "colab_type": "code",
        "outputId": "be8a6506-b79d-4459-9c0d-2c01a70007b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sm_pred[[0,1,2],[5,0,4]], pred[[0,1,2],[5,0,4]]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.3572, -2.3717, -2.3492], grad_fn=<IndexBackward>),\n",
              " tensor([-0.1327, -0.1624, -0.0999], grad_fn=<IndexBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxE7Rx2wpgdl",
        "colab_type": "code",
        "outputId": "7fbae17b-7df2-4e2b-c85c-6500f097a68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl6w0l-Epj8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(inp, target):\n",
        "  return -inp[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8MhFwJp3X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD3B8ADlp7_y",
        "colab_type": "code",
        "outputId": "3872bf78-a955-4b27-a221-c227e8351822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3035, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1oZch64qi_F",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_aDWYxtqQy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YafPGxAGqm2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJbguKSVq-Gi",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMP694fTq4O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJIuJb1uGzK",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AsdkjV5rywv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred),pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npw4PTa6uJI2",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our log_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQc7dHDqb-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NutUhxf7ta5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOguVzXmuMED",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYGToYQJtoUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred,-1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzOzKXkQur_3",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKl-fLkeuolj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yl5TFBqu5LJ",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   get the output of the model on a batch of inputs\n",
        "2.   compare the output to the labels we have and compute a loss\n",
        "3.   calculate the gradients of the loss with respect to every parameter of the model\n",
        "4.   update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqM6wqZEu2Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDQ6PagXti0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def accuracy(out, yb):\n",
        "  return (torch.argmax(out, dim=1) == yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJxXm73wcKg",
        "colab_type": "code",
        "outputId": "9477ae32-48fa-4c99-812d-17a74eff1f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "bs = 64\n",
        "xb = x_train[0:bs]\n",
        "pred = model(xb)\n",
        "pred[0], pred.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.1105, -0.0721, -0.2626, -0.1013,  0.0403, -0.1327,  0.0946, -0.0596,\n",
              "         -0.0949, -0.1240], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgxPLr-wk3h",
        "colab_type": "code",
        "outputId": "38207bdc-9aab-49b0-ca6b-6569f061d43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(pred, yb)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3028, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfjZhlHXwtsu",
        "colab_type": "code",
        "outputId": "edc43257-8ab4-45ea-8941-243335151b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(pred, yb)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1094)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy4Y6djowyJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5\n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2QuJQMxGry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epoch):\n",
        "  for i in range((n-1)//bs+1):\n",
        "    start_idx = i*bs\n",
        "    end_idx = start_idx+bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rLNiF43yoV8",
        "colab_type": "code",
        "outputId": "1abe5321-f061-4914-cdb5-9aa2dca2d0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2475, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfG7Zlo-y5gt",
        "colab_type": "text"
      },
      "source": [
        "## Using Parameters and Optim\n",
        "### Parameters\n",
        "Use `nn.Module.__setattr__` and move relu to functional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyWmoC2hyx5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjMgqIMwpMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oakH0xJeDI3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c5861a9-36c0-4cc7-eb48-245fc2c2eece"
      },
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f'{name} : {l}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1 : Linear(in_features=784, out_features=50, bias=True)\n",
            "l2 : Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWvRL2DoxaoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "979c332f-0f69-42dd-ed50-b3d04b99cf71"
      },
      "source": [
        "model"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeaWsPrCFnum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f292263-bfbe-4dda-88e1-f3e8b9e3a5c9"
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JC6tHGHFqgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs+1):\n",
        "      start_idx = i*bs\n",
        "      end_idx = start_idx + bs\n",
        "      xb = x_train[start_idx:end_idx]\n",
        "      yb = y_train[start_idx:end_idx]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      \n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "          model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ST_NPG0GhxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "043a3ef4-e1a5-429e-f31c-b8a867020907"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4532, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yIDjB3HV4L",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in  nn.Module so that the submodules you define are properly registered as parameters of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6W45BkeGuEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "402b04a9-3009-49ff-ba00-272ee115add8"
      },
      "source": [
        "for p in model.parameters():\n",
        "  print(f'{p.shape}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wasPhpaGqf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __setattr__(self, k, v):\n",
        "    if not k.startswith('_'):\n",
        "      self._modules[k] = v\n",
        "    super().__setattr__(k, v)\n",
        "      \n",
        "  def __repr__(self):\n",
        "    return f'{self._modules}'\n",
        "  \n",
        "  def parameters(self):\n",
        "    for l in self._modules.values():\n",
        "      for p in l.parameters():\n",
        "        yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-53cBTJVx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e09d665-2b1b-438f-b495-bceee6e37b0d"
      },
      "source": [
        "mdl = DummyModule(m, nh, 10)\n",
        "mdl"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyQtwj_Jag2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2e4922ea-3c9d-4b0d-cdca-300d83febc97"
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU61fDoqKOcv",
        "colab_type": "text"
      },
      "source": [
        "## Registering modules\n",
        "We can use the original layers approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhqAkQwhJyGo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c58ffd6d-2e30-4612-cae1-41308cab4e5d"
      },
      "source": [
        "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]\n",
        "layers"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZHUnHeKorB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i, l in enumerate(self.layers):\n",
        "      self.add_module(f'My_model_layer_{i}', l)\n",
        "      \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9jM8nmLfkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "58870fbe-b35a-46e9-95e2-7ea08bdb50eb"
      },
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (My_model_layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (My_model_layer_1): ReLU()\n",
              "  (My_model_layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yqOOwSL-2L",
        "colab_type": "text"
      },
      "source": [
        "### `nn.ModuleList`\n",
        "\n",
        "\n",
        "`nn.ModuleList` does this for us\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74LsFDssLjPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvpfHaPZM_Ww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2e6179bf-268f-44ff-a29c-7673246dfeb7"
      },
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t75KFWIdMlcA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1cf54d26-de29-4d75-835b-0517b902fca3"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3748, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzRxDcKiNReE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}