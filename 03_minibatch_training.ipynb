{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_minibatch_training",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kSKXyy5EjrHI",
        "HiwvFomemYL-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21cHknDhksD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpAQ2mO0h1GJ",
        "colab_type": "code",
        "outputId": "4b7c9a9b-8229-40ad-e6cd-7d326c4ccfdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56q5n6QFh3O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks/exp\")\n",
        "from nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklgC6rKjn7r",
        "colab_type": "text"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKXyy5EjrHI",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU7cdM-nhznp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqHQ_O2Sj46s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xZ6cWRvj_lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n, m = x_train.shape\n",
        "c= y_train.max() + 1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n3PZfYLkMga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKThfn4Wl3pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLUfC04vmAFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiwvFomemYL-",
        "colab_type": "text"
      },
      "source": [
        "## Cross Entropy loss\n",
        "\n",
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4X3M1n3meUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrPsrAehmzqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_F2_ptYnmNG",
        "colab_type": "code",
        "outputId": "4d2de2fe-ad9e-4d71-a7bd-570c744e6e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pred, sm_pred"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0275,  0.0092, -0.2147,  ..., -0.0495, -0.0214,  0.0644],\n",
              "         [-0.0113, -0.0682, -0.1864,  ...,  0.0903,  0.0189,  0.0840],\n",
              "         [-0.1886, -0.0273, -0.1646,  ..., -0.0007,  0.1491,  0.0414],\n",
              "         ...,\n",
              "         [-0.1881, -0.1181, -0.1009,  ..., -0.0299,  0.0957,  0.0286],\n",
              "         [-0.1767,  0.0650, -0.1534,  ..., -0.0832,  0.0837,  0.0529],\n",
              "         [-0.2526, -0.0246, -0.1625,  ...,  0.0350,  0.0774, -0.0049]],\n",
              "        grad_fn=<AddmmBackward>),\n",
              " tensor([[-2.2880, -2.2514, -2.4752,  ..., -2.3100, -2.2820, -2.1962],\n",
              "         [-2.2901, -2.3470, -2.4652,  ..., -2.1885, -2.2599, -2.1948],\n",
              "         [-2.4535, -2.2922, -2.4295,  ..., -2.2656, -2.1158, -2.2235],\n",
              "         ...,\n",
              "         [-2.4460, -2.3761, -2.3589,  ..., -2.2878, -2.1622, -2.2293],\n",
              "         [-2.4478, -2.2061, -2.4245,  ..., -2.3543, -2.1874, -2.2182],\n",
              "         [-2.5192, -2.2913, -2.4291,  ..., -2.2317, -2.1893, -2.2716]],\n",
              "        grad_fn=<LogBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_MP705pJZj",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09zYYQknnRg",
        "colab_type": "code",
        "outputId": "c8ec579c-523b-4c52-f610-2886b3c90273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVBHY2DbpaQO",
        "colab_type": "code",
        "outputId": "7126c050-7e19-4ad7-b2c8-2d156a1c8193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sm_pred[[0,1,2],[5,0,4]], pred[[0,1,2],[5,0,4]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.3705, -2.2901, -2.3373], grad_fn=<IndexBackward>),\n",
              " tensor([-0.1099, -0.0113, -0.0724], grad_fn=<IndexBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxE7Rx2wpgdl",
        "colab_type": "code",
        "outputId": "e2be4602-5a16-41c5-a6d5-a3dd7da117fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl6w0l-Epj8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(inp, target):\n",
        "  return -inp[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8MhFwJp3X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD3B8ADlp7_y",
        "colab_type": "code",
        "outputId": "a94ed977-1f41-41c7-ed29-be55707ed19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3075, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1oZch64qi_F",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_aDWYxtqQy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YafPGxAGqm2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJbguKSVq-Gi",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMP694fTq4O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJIuJb1uGzK",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AsdkjV5rywv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred),pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npw4PTa6uJI2",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our log_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQc7dHDqb-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NutUhxf7ta5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOguVzXmuMED",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYGToYQJtoUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred,-1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzOzKXkQur_3",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKl-fLkeuolj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yl5TFBqu5LJ",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   get the output of the model on a batch of inputs\n",
        "2.   compare the output to the labels we have and compute a loss\n",
        "3.   calculate the gradients of the loss with respect to every parameter of the model\n",
        "4.   update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqM6wqZEu2Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDQ6PagXti0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def accuracy(out, yb):\n",
        "  return (torch.argmax(out, dim=1) == yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJxXm73wcKg",
        "colab_type": "code",
        "outputId": "decc8266-ebbd-4c6d-ece3-519ed3c51f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "bs = 64\n",
        "xb = x_train[0:bs]\n",
        "pred = model(xb)\n",
        "pred[0], pred.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0275,  0.0092, -0.2147,  0.0060, -0.0349, -0.1099, -0.0676, -0.0495,\n",
              "         -0.0214,  0.0644], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgxPLr-wk3h",
        "colab_type": "code",
        "outputId": "6053d244-b172-4a49-9da5-dff0e772f174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(pred, yb)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3053, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfjZhlHXwtsu",
        "colab_type": "code",
        "outputId": "15755998-5562-481f-c326-8bcde0439730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(pred, yb)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy4Y6djowyJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5\n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2QuJQMxGry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs+1):\n",
        "    start_idx = i*bs\n",
        "    end_idx = start_idx+bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rLNiF43yoV8",
        "colab_type": "code",
        "outputId": "f78983e5-73d0-4de1-cd39-2b3a4651c00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1544, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfG7Zlo-y5gt",
        "colab_type": "text"
      },
      "source": [
        "## Using Parameters and Optim\n",
        "### Parameters\n",
        "Use `nn.Module.__setattr__` and move relu to functional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyWmoC2hyx5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjMgqIMwpMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oakH0xJeDI3i",
        "colab_type": "code",
        "outputId": "7cc5eea0-072b-4777-8246-c90e9a19d89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f'{name} : {l}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1 : Linear(in_features=784, out_features=50, bias=True)\n",
            "l2 : Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWvRL2DoxaoV",
        "colab_type": "code",
        "outputId": "2b6102f4-f9c1-4af5-bd06-4b06f2842be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeaWsPrCFnum",
        "colab_type": "code",
        "outputId": "5cd89b41-89ee-4a69-f962-e1ee9d2747e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JC6tHGHFqgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs+1):\n",
        "      start_idx = i*bs\n",
        "      end_idx = start_idx + bs\n",
        "      xb = x_train[start_idx:end_idx]\n",
        "      yb = y_train[start_idx:end_idx]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      \n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "          model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ST_NPG0GhxJ",
        "colab_type": "code",
        "outputId": "f3f1da09-71c4-4740-e23d-7ebb1798c0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3308, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yIDjB3HV4L",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in  nn.Module so that the submodules you define are properly registered as parameters of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6W45BkeGuEK",
        "colab_type": "code",
        "outputId": "bf698e9c-8721-4515-820c-2a7846378392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for p in model.parameters():\n",
        "  print(f'{p.shape}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wasPhpaGqf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __setattr__(self, k, v):\n",
        "    if not k.startswith('_'):\n",
        "      self._modules[k] = v\n",
        "    super().__setattr__(k, v)\n",
        "      \n",
        "  def __repr__(self):\n",
        "    return f'{self._modules}'\n",
        "  \n",
        "  def parameters(self):\n",
        "    for l in self._modules.values():\n",
        "      for p in l.parameters():\n",
        "        yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-53cBTJVx6",
        "colab_type": "code",
        "outputId": "be3334fd-16a4-4780-d66d-ea06a159a062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mdl = DummyModule(m, nh, 10)\n",
        "mdl"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyQtwj_Jag2",
        "colab_type": "code",
        "outputId": "e8400840-286c-4407-84b6-a062c6793894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU61fDoqKOcv",
        "colab_type": "text"
      },
      "source": [
        "## Registering modules\n",
        "We can use the original layers approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhqAkQwhJyGo",
        "colab_type": "code",
        "outputId": "3eef5f97-b19b-4b9b-b826-0b7b5307693d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]\n",
        "layers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZHUnHeKorB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i, l in enumerate(self.layers):\n",
        "      self.add_module(f'My_model_layer_{i}', l)\n",
        "      \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9jM8nmLfkR",
        "colab_type": "code",
        "outputId": "cfbe3128-cd81-4d8a-fcf5-bd89115d30cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (My_model_layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (My_model_layer_1): ReLU()\n",
              "  (My_model_layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yqOOwSL-2L",
        "colab_type": "text"
      },
      "source": [
        "### `nn.ModuleList`\n",
        "\n",
        "\n",
        "`nn.ModuleList` does this for us\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74LsFDssLjPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvpfHaPZM_Ww",
        "colab_type": "code",
        "outputId": "214c80db-442b-4b8e-cb28-d6e09c21bdb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t75KFWIdMlcA",
        "colab_type": "code",
        "outputId": "46aed871-7928-4568-ac25-ed1ccd02850f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3393, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBgmzsqDbjW-",
        "colab_type": "text"
      },
      "source": [
        "### `nn.Sequential`\n",
        "`nn.Sequential` is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afWaUEMHbsNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeAo70YVb4vE",
        "colab_type": "code",
        "outputId": "0faf1ae4-8dba-4811-e4f8-5c39095c21d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3767, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzRxDcKiNReE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B84CglM2a0EP",
        "colab_type": "code",
        "outputId": "8e1ff55b-f2a2-41af-a1fb-74d15a7c1d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ameBs96ua2zO",
        "colab_type": "text"
      },
      "source": [
        "### optim\n",
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "and instead use just:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teMi3R4qa1yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "  def __init__(self, params, lr=0.5):\n",
        "    self.params, self.lr = list(params), lr\n",
        "    \n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        p -= p.grad * lr\n",
        "        \n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8b6uWu9eaHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imodX1k0em_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvvCep3hesyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKquHJSHgWMd",
        "colab_type": "code",
        "outputId": "20a512ec-ec0b-432d-c60e-13942759ea85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2145, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiD7OO6ig6vr",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTWy43P-euq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQCnagqhEwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Adj99NIhHlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
        "  return model, optim.SGD(model.parameters(), lr= lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw1nSopehlEz",
        "colab_type": "code",
        "outputId": "21416567-e484-42b7-9d8e-b4848d3894a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model, opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2815, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87GL3AqQiFcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvN5d64jEah",
        "colab_type": "code",
        "outputId": "11b88805-7b26-4bd0-8c88-37057b3e250b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_func(model(xb), yb) , accuracy(model(xb), yb)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2113, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqKNfksjZTY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Randomized tests can be very useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uQX1S6z35yk",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OO1AI42zacd",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "```\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "```    \n",
        "Instead, let's do these two steps together, by introducing a Dataset class:\n",
        "\n",
        "`xb,yb = train_ds[i*bs : i*bs+bs]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QcDajpjUUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class Dataset():\n",
        "  def __init__(self, x, y):\n",
        "    self.x, self.y = x, y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCMz82gPhYla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "assert len(train_ds) == len(x_train)\n",
        "assert len(valid_ds) == len(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWt1JQpc0l2q",
        "colab_type": "code",
        "outputId": "b67ff173-51cf-4870-b215-3f250a3804a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "xb, yb = train_ds[0:5]\n",
        "assert xb.shape == (5, 28 * 28)\n",
        "assert yb.shape == (5,)\n",
        "xb, yb"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yx5cLAP1H-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5bXxdL2Poy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    xb, yb = train_ds[i * bs :  i*bs + bs]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHhKfVeo3YAJ",
        "colab_type": "code",
        "outputId": "84afb8ba-cb45-4f8e-b5b8-355ae8d1f765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc > 0.7\n",
        "loss, acc"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2106, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvrfehIY4CMS",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader\n",
        "Previously, our loop iterated over batches (bx, yb) like this:\n",
        "\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "  xb, yb = train_ds[i*bs : i*bs+bs]\n",
        "  ...\n",
        "\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader\n",
        "\n",
        "```\n",
        "for xb, yb in train_dl:\n",
        "  ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIosMX73oM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs):\n",
        "    self.ds, self.bs = ds, bs\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs):\n",
        "      yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6PqtVW5HWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMScMIY5QAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(valid_dl))\n",
        "assert xb.shape == (bs, 28 * 28)\n",
        "assert yb.shape == (bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_eJP0KZ5gWA",
        "colab_type": "code",
        "outputId": "be1f68ac-963d-4865-d3cf-2546c11f0cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(xb[0].view(28, 28))\n",
        "yb[0]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIN8JwUP51dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhhgPh2Q5_vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBA2tGo6Xbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eu3f28k6xxO",
        "colab_type": "code",
        "outputId": "9ce081a6-041e-4378-ec7e-75cf03c735e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc > 0.7\n",
        "loss, acc"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1226, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbP9bOAb6_lS",
        "colab_type": "text"
      },
      "source": [
        "### Random Sampling\n",
        "\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9oeQi868mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "  def __init__(self, ds, bs, shuffle = False ):\n",
        "    self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
        "    \n",
        "  def __iter__(self):\n",
        "    self.idx = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "    for i in range(0, self.n, self.bs):\n",
        "      yield self.idx[i:i+self.bs]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYT7yGoR8ecX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEWHw7qB8j4o",
        "colab_type": "code",
        "outputId": "d48f93d7-b5e4-4221-ffe2-b0aa98f34dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = Sampler(small_ds, 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2bgT1e8sSu",
        "colab_type": "code",
        "outputId": "0aa5f0de-45fd-4edb-dc56-0179ce71c4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s = Sampler(small_ds, 3, True)\n",
        "[o for o in s]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([7, 1, 0]), tensor([8, 2, 5]), tensor([6, 3, 4]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_PctnaA9Rf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "  xs, ys = zip(*b)\n",
        "  return torch.stack(xs), torch.stack(ys)\n",
        "\n",
        "\n",
        "class DataLoader():\n",
        "  def __init__(self, ds, sampler, collate_fn = collate):\n",
        "    self.ds, self.sampler, self.collate_fn = ds, sampler, collate_fn\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for s in self.sampler:\n",
        "      yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVB7n5ARRfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sample = Sampler(train_ds, bs, shuffle = True)\n",
        "valid_sample = Sampler(valid_ds, bs, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISDPutOyRl2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler = train_sample, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler = valid_sample, collate_fn=collate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-pKZpsaRryP",
        "colab_type": "code",
        "outputId": "c7250a46-bab5-4814-9d80-d29df82badbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "xb, yb =  next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVoFfNLaSNgH",
        "colab_type": "code",
        "outputId": "f66dbae2-61ea-4d56-801b-fd8e5ffee2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "xb, yb =  next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrOqBzjzTPAq",
        "colab_type": "code",
        "outputId": "89c86a47-764d-42b9-9e2a-e836a032e3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss, acc"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0927, grad_fn=<NllLossBackward>), tensor(0.9844))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75CiFqr7TnB7",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXzWjfTjTbUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QUyaxZ6T38m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acV16XN4UfNB",
        "colab_type": "code",
        "outputId": "9af737c7-2d0e-469c-f972-15bcc3d27835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb) , accuracy(model(xb), yb)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5657, grad_fn=<NllLossBackward>), tensor(0.8906))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ5hc3Y7Uzrd",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrH4Ibu1Ut0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR2Mw7VzVSnN",
        "colab_type": "code",
        "outputId": "40657b37-1f51-4c57-ffd5-2649ef133a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss, acc"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1032, grad_fn=<NllLossBackward>), tensor(0.9688))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzwhG-YNVhwV",
        "colab_type": "text"
      },
      "source": [
        "## Validation\n",
        "\n",
        "\n",
        "You **always** should also have a validation set, in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLm4LIdhVc9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "      \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      tot_loss, tot_acc = 0., 0.\n",
        "      for xb, yb in valid_dl:\n",
        "        pred = model(xb)\n",
        "        tot_loss += loss_func(pred, yb)\n",
        "        tot_acc += accuracy(pred, yb)\n",
        "        \n",
        "        \n",
        "    nv = len(valid_dl)\n",
        "    print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "  return tot_loss/nv, tot_acc/nv\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc9e9l-AWvB1",
        "colab_type": "text"
      },
      "source": [
        "Question: Are these validation results correct if batch size varies?\n",
        "\n",
        "get_dls returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M__fmloWuKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "  return (DataLoader(train_ds, batch_size = bs, shuffle = True, **kwargs),\n",
        "         DataLoader(valid_ds, batch_size = bs, shuffle = False, **kwargs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21fD4DdzXUTh",
        "colab_type": "code",
        "outputId": "a2335da0-5bec-4e32-f574-41b2babeb093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.1645) tensor(0.9525)\n",
            "1 tensor(0.1786) tensor(0.9491)\n",
            "2 tensor(0.1253) tensor(0.9650)\n",
            "3 tensor(0.1029) tensor(0.9701)\n",
            "4 tensor(0.1104) tensor(0.9688)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIYKDEhmXszp",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyi-MQjYMXk",
        "colab_type": "code",
        "outputId": "5a755980-b3bf-4605-842f-c0842c572939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=ebccbb3b88bf0c8ca93b3756f74d5305cb7087417188ca51b42ff1bd334c355b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-lvWuGpXjYu",
        "colab_type": "code",
        "outputId": "16fa62d1-fb50-41a4-bcf0-4e4a1c0a04bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python \"/content/drive/My Drive/Colab Notebooks/notebook2script.py\" \"/content/drive/My Drive/Colab Notebooks/03_minibatch_training.ipynb\""
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted /content/drive/My Drive/Colab Notebooks/03_minibatch_training.ipynb to /content/drive/My Drive/Colab Notebooks/exp/nb_03.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}