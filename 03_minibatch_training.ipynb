{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_minibatch_training",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "kSKXyy5EjrHI",
        "HiwvFomemYL-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21cHknDhksD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpAQ2mO0h1GJ",
        "colab_type": "code",
        "outputId": "962c112c-677c-47c3-e50a-d20980b6230b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#export\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56q5n6QFh3O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/drive/My Drive/Colab Notebooks/exp\")\n",
        "from nb_02 import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklgC6rKjn7r",
        "colab_type": "text"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKXyy5EjrHI",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU7cdM-nhznp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqHQ_O2Sj46s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xZ6cWRvj_lY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n, m = x_train.shape\n",
        "c= y_train.max() + 1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n3PZfYLkMga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh, n_out)]\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers: x = l(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKThfn4Wl3pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLUfC04vmAFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiwvFomemYL-",
        "colab_type": "text"
      },
      "source": [
        "## Cross Entropy loss\n",
        "\n",
        "First, we will need to compute the softmax of our activations. This is defined by:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
        "or more concisely:\n",
        "\n",
        "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum_{0 \\leq j \\leq n-1} e^{x_{j}}}$$\n",
        "In practice, we will need the log of the softmax when we calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4X3M1n3meUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return (x.exp()/(x.exp().sum(-1, keepdim=True))).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrPsrAehmzqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_F2_ptYnmNG",
        "colab_type": "code",
        "outputId": "3c51d5a2-01df-4286-d133-347bee5b661c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "pred, sm_pred"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2326, -0.0639,  0.0851,  ...,  0.1524, -0.1599, -0.1138],\n",
              "         [-0.1786,  0.0279,  0.0122,  ...,  0.2360, -0.1821, -0.1633],\n",
              "         [-0.2282, -0.0040,  0.1148,  ...,  0.0736, -0.1536, -0.0498],\n",
              "         ...,\n",
              "         [-0.1336, -0.0350,  0.0847,  ...,  0.1606, -0.1036, -0.1426],\n",
              "         [-0.1736,  0.0304,  0.0163,  ...,  0.2221, -0.1407, -0.0938],\n",
              "         [-0.2325, -0.0621, -0.0049,  ...,  0.1565, -0.2045, -0.1562]],\n",
              "        grad_fn=<AddmmBackward>),\n",
              " tensor([[-2.5069, -2.3381, -2.1892,  ..., -2.1218, -2.4342, -2.3881],\n",
              "         [-2.4701, -2.2635, -2.2792,  ..., -2.0555, -2.4735, -2.4547],\n",
              "         [-2.5058, -2.2816, -2.1628,  ..., -2.2040, -2.4312, -2.3274],\n",
              "         ...,\n",
              "         [-2.4284, -2.3298, -2.2102,  ..., -2.1342, -2.3984, -2.4374],\n",
              "         [-2.4702, -2.2663, -2.2803,  ..., -2.0746, -2.4373, -2.3904],\n",
              "         [-2.5105, -2.3401, -2.2829,  ..., -2.1215, -2.4825, -2.4342]],\n",
              "        grad_fn=<LogBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu_MP705pJZj",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09zYYQknnRg",
        "colab_type": "code",
        "outputId": "464749eb-1261-4796-a4fa-f233c9f929d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVBHY2DbpaQO",
        "colab_type": "code",
        "outputId": "23c33e74-ec4c-4e1c-e4b6-b49613ffc702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "sm_pred[[0,1,2],[5,0,4]], pred[[0,1,2],[5,0,4]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.4875, -2.4701, -2.2169], grad_fn=<IndexBackward>),\n",
              " tensor([-0.2133, -0.1786,  0.0607], grad_fn=<IndexBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxE7Rx2wpgdl",
        "colab_type": "code",
        "outputId": "cd60f107-78f6-4ce4-e8a7-02cc4737a772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl6w0l-Epj8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(inp, target):\n",
        "  return -inp[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8MhFwJp3X-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD3B8ADlp7_y",
        "colab_type": "code",
        "outputId": "27196cd5-e736-4db5-eedf-a5b8447cb659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3051, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1oZch64qi_F",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_aDWYxtqQy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1, keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YafPGxAGqm2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJbguKSVq-Gi",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMP694fTq4O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "  m = x.max(-1)[0]\n",
        "  return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJIuJb1uGzK",
        "colab_type": "text"
      },
      "source": [
        "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AsdkjV5rywv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred),pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npw4PTa6uJI2",
        "colab_type": "text"
      },
      "source": [
        "So we can use it for our log_softmax function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQc7dHDqb-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.logsumexp(-1, keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NutUhxf7ta5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOguVzXmuMED",
        "colab_type": "text"
      },
      "source": [
        "Then use PyTorch's implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYGToYQJtoUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.nll_loss(F.log_softmax(pred,-1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzOzKXkQur_3",
        "colab_type": "text"
      },
      "source": [
        "In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKl-fLkeuolj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yl5TFBqu5LJ",
        "colab_type": "text"
      },
      "source": [
        "## Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   get the output of the model on a batch of inputs\n",
        "2.   compare the output to the labels we have and compute a loss\n",
        "3.   calculate the gradients of the loss with respect to every parameter of the model\n",
        "4.   update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqM6wqZEu2Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDQ6PagXti0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def accuracy(out, yb):\n",
        "  return (torch.argmax(out, dim=1) == yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZJxXm73wcKg",
        "colab_type": "code",
        "outputId": "93329458-80e2-48ec-b6c9-0cabaf7da3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "bs = 64\n",
        "xb = x_train[0:bs]\n",
        "pred = model(xb)\n",
        "pred[0], pred.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2326, -0.0639,  0.0851,  0.1682,  0.0158, -0.2133, -0.0149,  0.1524,\n",
              "         -0.1599, -0.1138], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgxPLr-wk3h",
        "colab_type": "code",
        "outputId": "d4a8da7b-ad74-4649-e91d-db6186b9041c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(pred, yb)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3039, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfjZhlHXwtsu",
        "colab_type": "code",
        "outputId": "a95bd4bc-954e-4f1f-a519-b79b7e11ac06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy(pred, yb)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy4Y6djowyJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.5\n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2QuJQMxGry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs+1):\n",
        "    start_idx = i*bs\n",
        "    end_idx = start_idx+bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    loss = loss_func(model(xb), yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad * lr\n",
        "          l.bias -= l.bias.grad * lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rLNiF43yoV8",
        "colab_type": "code",
        "outputId": "b546d68d-f9de-4258-c611-c8983eb30a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1751, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfG7Zlo-y5gt",
        "colab_type": "text"
      },
      "source": [
        "## Using Parameters and Optim\n",
        "### Parameters\n",
        "Use `nn.Module.__setattr__` and move relu to functional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyWmoC2hyx5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjMgqIMwpMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oakH0xJeDI3i",
        "colab_type": "code",
        "outputId": "240c4e73-ca8d-48f8-bf0c-c0a9828e8318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "for name, l in model.named_children():\n",
        "  print(f'{name} : {l}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1 : Linear(in_features=784, out_features=50, bias=True)\n",
            "l2 : Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWvRL2DoxaoV",
        "colab_type": "code",
        "outputId": "ddeae3fd-8e8b-46c8-cfc8-0e9baf5d7b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeaWsPrCFnum",
        "colab_type": "code",
        "outputId": "58c0afa3-b33e-4ae2-d7df-a89b0ddc7c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JC6tHGHFqgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs+1):\n",
        "      start_idx = i*bs\n",
        "      end_idx = start_idx + bs\n",
        "      xb = x_train[start_idx:end_idx]\n",
        "      yb = y_train[start_idx:end_idx]\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      \n",
        "      loss.backward()\n",
        "      with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "          p -= p.grad * lr\n",
        "          model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ST_NPG0GhxJ",
        "colab_type": "code",
        "outputId": "569cfc55-1d2f-4948-b48e-04d062eadf0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3877, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8yIDjB3HV4L",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the `__setattr__` function in  nn.Module so that the submodules you define are properly registered as parameters of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6W45BkeGuEK",
        "colab_type": "code",
        "outputId": "0b666f94-46c3-4d53-a771-f49be6f6463b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for p in model.parameters():\n",
        "  print(f'{p.shape}')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 784])\n",
            "torch.Size([50])\n",
            "torch.Size([10, 50])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wasPhpaGqf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "  def __init__(self, n_in, nh, n_out):\n",
        "    self._modules = {}\n",
        "    self.l1 = nn.Linear(n_in, nh)\n",
        "    self.l2 = nn.Linear(nh, n_out)\n",
        "    \n",
        "  def __setattr__(self, k, v):\n",
        "    if not k.startswith('_'):\n",
        "      self._modules[k] = v\n",
        "    super().__setattr__(k, v)\n",
        "      \n",
        "  def __repr__(self):\n",
        "    return f'{self._modules}'\n",
        "  \n",
        "  def parameters(self):\n",
        "    for l in self._modules.values():\n",
        "      for p in l.parameters():\n",
        "        yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN-53cBTJVx6",
        "colab_type": "code",
        "outputId": "de2d7529-5484-4525-ff6f-a985c1764114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mdl = DummyModule(m, nh, 10)\n",
        "mdl"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wyQtwj_Jag2",
        "colab_type": "code",
        "outputId": "83c9a86b-5299-4a78-8a70-709119645cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU61fDoqKOcv",
        "colab_type": "text"
      },
      "source": [
        "## Registering modules\n",
        "We can use the original layers approach, but we have to register the modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhqAkQwhJyGo",
        "colab_type": "code",
        "outputId": "fb1eaaab-47ba-45ff-948c-6157fddd1240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10)]\n",
        "layers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=50, bias=True),\n",
              " ReLU(),\n",
              " Linear(in_features=50, out_features=10, bias=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OZHUnHeKorB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    for i, l in enumerate(self.layers):\n",
        "      self.add_module(f'My_model_layer_{i}', l)\n",
        "      \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC9jM8nmLfkR",
        "colab_type": "code",
        "outputId": "62ad2262-f628-446b-935e-0d47d772cacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = Model(layers)\n",
        "model"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (My_model_layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (My_model_layer_1): ReLU()\n",
              "  (My_model_layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2yqOOwSL-2L",
        "colab_type": "text"
      },
      "source": [
        "### `nn.ModuleList`\n",
        "\n",
        "\n",
        "`nn.ModuleList` does this for us\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74LsFDssLjPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "  def __init__(self, layers):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList(layers)\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    for l in self.layers:\n",
        "      x = l(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvpfHaPZM_Ww",
        "colab_type": "code",
        "outputId": "d296123a-2bc0-439d-c755-55d65ec08c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = SequentialModel(layers)\n",
        "model"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t75KFWIdMlcA",
        "colab_type": "code",
        "outputId": "8ae970f8-2b7e-46c6-8930-f39c1f197288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4695, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBgmzsqDbjW-",
        "colab_type": "text"
      },
      "source": [
        "### `nn.Sequential`\n",
        "`nn.Sequential` is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afWaUEMHbsNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeAo70YVb4vE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4de20bc0-00c2-4874-c1b5-443de271c12e"
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4116, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzRxDcKiNReE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B84CglM2a0EP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "669179f5-4faf-435c-fc48-f7172934c64a"
      },
      "source": [
        "model"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ameBs96ua2zO",
        "colab_type": "text"
      },
      "source": [
        "### optim\n",
        "Let's replace our previous manually coded optimization step:\n",
        "\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "and instead use just:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teMi3R4qa1yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "  def __init__(self, params, lr=0.5):\n",
        "    self.params, self.lr = list(params), lr\n",
        "    \n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params:\n",
        "        p -= p.grad * lr\n",
        "        \n",
        "  def zero_grad(self):\n",
        "    for p in self.params:\n",
        "      p.grad.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8b6uWu9eaHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imodX1k0em_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvvCep3hesyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKquHJSHgWMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9d16527-679c-4c9d-f0ee-8563ac440db9"
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1751, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiD7OO6ig6vr",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTWy43P-euq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQCnagqhEwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Adj99NIhHlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))\n",
        "  return model, optim.SGD(model.parameters(), lr= lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw1nSopehlEz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61ad666e-09f7-42d1-ca66-8b0f22e436ec"
      },
      "source": [
        "model, opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2474, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87GL3AqQiFcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    start_idx = i * bs\n",
        "    end_idx = start_idx + bs\n",
        "    xb = x_train[start_idx:end_idx]\n",
        "    yb = y_train[start_idx:end_idx]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvN5d64jEah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "427e0361-53de-4fd1-dcd0-83952311785e"
      },
      "source": [
        "loss_func(model(xb), yb) , accuracy(model(xb), yb)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1221, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzqKNfksjZTY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Randomized tests can be very useful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uQX1S6z35yk",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OO1AI42zacd",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "It's clunky to iterate through minibatches of x and y values separately:\n",
        "```\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "```    \n",
        "Instead, let's do these two steps together, by introducing a Dataset class:\n",
        "\n",
        "`xb,yb = train_ds[i*bs : i*bs+bs]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_QcDajpjUUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class Dataset():\n",
        "  def __init__(self, x, y):\n",
        "    self.x, self.y = x, y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCMz82gPhYla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
        "assert len(train_ds) == len(x_train)\n",
        "assert len(valid_ds) == len(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWt1JQpc0l2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6cf28a8c-1729-4fb4-cdf1-14aecf56ca01"
      },
      "source": [
        "xb, yb = train_ds[0:5]\n",
        "assert xb.shape == (5, 28 * 28)\n",
        "assert yb.shape == (5,)\n",
        "xb, yb"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yx5cLAP1H-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5bXxdL2Poy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for i in range((n-1)//bs + 1):\n",
        "    xb, yb = train_ds[i * bs :  i*bs + bs]\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    \n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHhKfVeo3YAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5294c541-1284-42fb-b53d-1f6b39bb0019"
      },
      "source": [
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc > 0.7\n",
        "loss, acc"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0980, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvrfehIY4CMS",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader\n",
        "Previously, our loop iterated over batches (bx, yb) like this:\n",
        "\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "  xb, yb = train_ds[i*bs : i*bs+bs]\n",
        "  ...\n",
        "\n",
        "```\n",
        "\n",
        "Let's make our loop much cleaner, using a data loader\n",
        "\n",
        "```\n",
        "for xb, yb in train_dl:\n",
        "  ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYIosMX73oM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs):\n",
        "    self.ds, self.bs = ds, bs\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs):\n",
        "      yield self.ds[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6PqtVW5HWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOMScMIY5QAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb, yb = next(iter(valid_dl))\n",
        "assert xb.shape == (bs, 28 * 28)\n",
        "assert yb.shape == (bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_eJP0KZ5gWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "b7924a9e-a882-4a60-c680-c257db48d7b6"
      },
      "source": [
        "plt.imshow(xb[0].view(28, 28))\n",
        "yb[0]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIN8JwUP51dx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhhgPh2Q5_vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIBA2tGo6Xbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Eu3f28k6xxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c93cac8a-a92e-49ce-f3b6-3f89e180a4ba"
      },
      "source": [
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc > 0.7\n",
        "loss, acc"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1017, grad_fn=<NllLossBackward>), tensor(0.9844))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbP9bOAb6_lS",
        "colab_type": "text"
      },
      "source": [
        "### Random Sampling\n",
        "\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_9oeQi868mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "  def __init__(self, ds, bs, shuffle = False ):\n",
        "    self.n, self.bs, self.shuffle = len(ds), bs, shuffle\n",
        "    \n",
        "  def __iter__(self):\n",
        "    self.idx = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "    for i in range(0, self.n, self.bs):\n",
        "      yield self.idx[i:i+self.bs]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYT7yGoR8ecX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEWHw7qB8j4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed16b75b-6006-45c5-98aa-b39144907d2f"
      },
      "source": [
        "s = Sampler(small_ds, 3, False)\n",
        "[o for o in s]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i2bgT1e8sSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3e61687-33d7-4d94-9159-940930109ac1"
      },
      "source": [
        "s = Sampler(small_ds, 3, True)\n",
        "[o for o in s]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([2, 8, 3]), tensor([7, 5, 1]), tensor([9, 0, 4]), tensor([6])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_PctnaA9Rf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "  xs, ys = zip(*b)\n",
        "  return torch.stack(xs), torch.stack(ys)\n",
        "\n",
        "\n",
        "class DataLoader():\n",
        "  def __init__(self, ds, sampler, collate_fn = collate):\n",
        "    self.ds, self.sampler, self.collate_fn = ds, sampler, collate_fn\n",
        "    \n",
        "  def __iter__(self):\n",
        "    for s in self.sampler:\n",
        "      yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcVB7n5ARRfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sample = Sampler(train_ds, bs, shuffle = True)\n",
        "valid_sample = Sampler(valid_ds, bs, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISDPutOyRl2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler = train_sample, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler = valid_sample, collate_fn=collate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-pKZpsaRryP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "d575fcef-6cb4-437d-9ba8-0b1cd8cf572d"
      },
      "source": [
        "xb, yb =  next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVoFfNLaSNgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "8b1336fa-a8b5-447e-900a-38f1d286efef"
      },
      "source": [
        "xb, yb =  next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwy8VZfilov4DzpXz7ToliZoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrOqBzjzTPAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "859ea90f-a311-4aef-9fa0-4db7d837ced9"
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss, acc"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1192, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75CiFqr7TnB7",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXzWjfTjTbUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QUyaxZ6T38m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acV16XN4UfNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bf7f230-e241-4287-9534-9c43afc3d27c"
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb) , accuracy(model(xb), yb)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1891, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ5hc3Y7Uzrd",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrH4Ibu1Ut0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR2Mw7VzVSnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e5264a7-b893-4986-e2db-a067b1d87753"
      },
      "source": [
        "model, opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss, acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss, acc"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1569, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzwhG-YNVhwV",
        "colab_type": "text"
      },
      "source": [
        "## Validation\n",
        "\n",
        "\n",
        "You **always** should also have a validation set, in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLm4LIdhVc9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      loss = loss_func(model(xb), yb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "      \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      tot_loss, tot_acc = 0., 0.\n",
        "      for xb, yb in valid_dl:\n",
        "        pred = model(xb)\n",
        "        tot_loss += loss_func(pred, yb)\n",
        "        tot_acc += accuracy(pred, yb)\n",
        "        \n",
        "        \n",
        "    nv = len(valid_dl)\n",
        "    print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "  return tot_loss/nv, tot_acc/nv\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mc9e9l-AWvB1",
        "colab_type": "text"
      },
      "source": [
        "Question: Are these validation results correct if batch size varies?\n",
        "\n",
        "get_dls returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M__fmloWuKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "  return (DataLoader(train_ds, batch_size = bs, shuffle = True, **kwargs),\n",
        "         DataLoader(valid_ds, batch_size = bs, shuffle = False, **kwargs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21fD4DdzXUTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b5f51cd8-511c-4f45-ad4b-b68f5a2cdae6"
      },
      "source": [
        "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "loss, acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.1852) tensor(0.9460)\n",
            "1 tensor(0.1090) tensor(0.9670)\n",
            "2 tensor(0.1144) tensor(0.9669)\n",
            "3 tensor(0.1042) tensor(0.9709)\n",
            "4 tensor(0.1154) tensor(0.9687)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIYKDEhmXszp",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyi-MQjYMXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "e42e60ab-1af4-4f7b-d3c0-c5fa5ddbdf23"
      },
      "source": [
        "!pip install fire"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=f39d6a337020213e128833004b94f24a9aaeba8e48681c3800ead462c8b35bed\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-lvWuGpXjYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "461c8441-438a-4614-d90a-21cb376820ed"
      },
      "source": [
        "!python \"/content/drive/My Drive/Colab Notebooks/notebook2script.py\" \"/content/drive/My Drive/Colab Notebooks/03_minibatch_training.ipynb\""
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted /content/drive/My Drive/Colab Notebooks/03_minibatch_training.ipynb to /content/drive/My Drive/Colab Notebooks/exp/nb_03.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}